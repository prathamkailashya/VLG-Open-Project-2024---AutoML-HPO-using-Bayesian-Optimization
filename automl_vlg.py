# -*- coding: utf-8 -*-
"""AutoML_VLG.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RE9O_mN1lgCCSnJVmOvv_bHqGjCuu1Aj

# Basic Simulation Run on load_wine() dataset
"""

from sklearn.datasets import load_wine
from sklearn.model_selection import train_test_split

# Load dataset
data = load_wine()
X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.2, random_state=42)

from sklearn.ensemble import RandomForestClassifier

# Define the model
model = RandomForestClassifier()

# Define parameter grid
param_grid = {
    'n_estimators': [10, 50, 100],
    'max_depth': [None, 10, 20, 30],
    'min_samples_split': [2, 5, 10]
}

from sklearn.model_selection import GridSearchCV, RandomizedSearchCV
from sklearn.metrics import roc_auc_score, make_scorer

# Define the scorer
scorer = make_scorer(roc_auc_score, multi_class='ovo', needs_proba=True)

# Grid Search
grid_search = GridSearchCV(model, param_grid, scoring=scorer, cv=5)
grid_search.fit(X_train, y_train)
print("Best parameters (Grid Search):", grid_search.best_params_)

# Random Search
random_search = RandomizedSearchCV(model, param_grid, scoring=scorer, cv=5, n_iter=10, random_state=42)
random_search.fit(X_train, y_train)
print("Best parameters (Random Search):", random_search.best_params_)

import numpy as np
from scipy.stats import norm
from sklearn.gaussian_process import GaussianProcessRegressor
from sklearn.gaussian_process.kernels import Matern

# Define the function to be optimized
def black_box_function(params):
    n_estimators, max_depth, min_samples_split = params[0], params[1], params[2]
    model = RandomForestClassifier(n_estimators=int(n_estimators), max_depth=int(max_depth), min_samples_split=int(min_samples_split))
    model.fit(X_train, y_train)
    preds = model.predict_proba(X_test)
    return -roc_auc_score(y_test, preds, multi_class='ovo')  # Negative because we minimize in optimization

# Bayesian Optimization
class BayesianOptimization:
    def __init__(self, func, bounds, n_iter=25, kernel=None):
        self.func = func
        self.bounds = bounds
        self.n_iter = n_iter
        self.kernel = kernel or Matern()
        self.gp = GaussianProcessRegressor(kernel=self.kernel)
        self.x_samples = []
        self.y_samples = []

    def propose_location(self, acquisition_func):
        x_candidates = np.random.uniform(self.bounds[:, 0], self.bounds[:, 1], size=(1000, self.bounds.shape[0]))
        acquisition_values = acquisition_func(x_candidates)
        return x_candidates[np.argmax(acquisition_values)].reshape(1, -1)

    def optimize(self):
        for _ in range(self.n_iter):
            if len(self.x_samples) > 0:
                self.gp.fit(np.array(self.x_samples), np.array(self.y_samples))
                x_next = self.propose_location(self.expected_improvement)
            else:
                x_next = np.random.uniform(self.bounds[:, 0], self.bounds[:, 1], size=(1, self.bounds.shape[0]))

            y_next = self.func(x_next[0])
            self.x_samples.append(x_next[0])
            self.y_samples.append(y_next)

        return self.x_samples, self.y_samples

    def expected_improvement(self, x, xi=0.01):
        mu, sigma = self.gp.predict(x, return_std=True)
        mu_sample_opt = np.min(self.y_samples)

        with np.errstate(divide='warn'):
            imp = mu_sample_opt - mu - xi
            Z = imp / sigma
            ei = imp * norm.cdf(Z) + sigma * norm.pdf(Z)
            ei[sigma == 0.0] = 0.0

        return ei

# Define the bounds of the search space
bounds = np.array([[10, 100], [1, 30], [2, 10]])

# Perform Bayesian optimization
bo = BayesianOptimization(black_box_function, bounds)
x_samples, y_samples = bo.optimize()
best_params = x_samples[np.argmin(y_samples)]
print("Best parameters (Bayesian Optimization):", best_params)

from sklearn.model_selection import cross_val_score

# Evaluate Grid Search Model
grid_model = grid_search.best_estimator_
grid_auc = cross_val_score(grid_model, X_train, y_train, cv=5, scoring=scorer)
print("Grid Search AUC:", grid_auc.mean())

# Evaluate Random Search Model
random_model = random_search.best_estimator_
random_auc = cross_val_score(random_model, X_train, y_train, cv=5, scoring=scorer)
print("Random Search AUC:", random_auc.mean())

# Evaluate Bayesian Optimization Model
bo_model = RandomForestClassifier(n_estimators=int(best_params[0]), max_depth=int(best_params[1]), min_samples_split=int(best_params[2]))
bo_model.fit(X_train, y_train)
bo_preds = bo_model.predict_proba(X_test)
bo_auc = roc_auc_score(y_test, bo_preds, multi_class='ovo')
print("Bayesian Optimization AUC:", bo_auc)

import matplotlib.pyplot as plt

# Plot AUC Scores
methods = ['Grid Search', 'Random Search', 'Bayesian Optimization']
auc_scores = [grid_auc.mean(), random_auc.mean(), bo_auc]

plt.bar(methods, auc_scores, color=['blue', 'green', 'red'])
plt.ylabel('AUC Score')
plt.title('Comparison of HPO Techniques')
plt.show()

from sklearn.ensemble import RandomForestRegressor
from scipy.stats import norm
import numpy as np

class RandomForestOptimization:
    def __init__(self, func, bounds, n_iter=25):
        self.func = func
        self.bounds = bounds
        self.n_iter = n_iter
        self.rf = RandomForestRegressor()
        self.x_samples = []
        self.y_samples = []

    def propose_location(self):
        x_candidates = np.random.uniform(self.bounds[:, 0], self.bounds[:, 1], size=(1000, self.bounds.shape[0]))
        y_preds = self.rf.predict(x_candidates)
        return x_candidates[np.argmax(y_preds)].reshape(1, -1)

    def optimize(self):
        for _ in range(self.n_iter):
            if len(self.x_samples) > 0:
                self.rf.fit(np.array(self.x_samples), np.array(self.y_samples))
                x_next = self.propose_location()
            else:
                x_next = np.random.uniform(self.bounds[:, 0], self.bounds[:, 1], size=(1, self.bounds.shape[0]))

            y_next = self.func(x_next[0])
            self.x_samples.append(x_next[0])
            self.y_samples.append(y_next)

        return self.x_samples, self.y_samples

# Perform Random Forest Optimization
rfo = RandomForestOptimization(black_box_function, bounds)
x_samples_rfo, y_samples_rfo = rfo.optimize()
best_params_rfo = x_samples_rfo[np.argmin(y_samples_rfo)]
print("Best parameters (Random Forest Optimization):", best_params_rfo)

import numpy as np
from scipy.stats import norm

class TPEOptimization:
    def __init__(self, func, bounds, n_iter=25, gamma=0.25, bandwidth=0.1):
        self.func = func
        self.bounds = bounds
        self.n_iter = n_iter
        self.gamma = gamma
        self.bandwidth = bandwidth
        self.x_samples = []
        self.y_samples = []

    def parzen_window(self, samples, x):
        return np.mean([norm.pdf(x, loc=sample, scale=self.bandwidth) for sample in samples])

    def suggest(self):
        if len(self.y_samples) < 1:
            return np.random.uniform(self.bounds[:, 0], self.bounds[:, 1], size=self.bounds.shape[0])

        n_good = int(np.ceil(self.gamma * len(self.y_samples)))
        y_sorted_indices = np.argsort(self.y_samples)
        good_samples = [self.x_samples[i] for i in y_sorted_indices[:n_good]]
        bad_samples = [self.x_samples[i] for i in y_sorted_indices[n_good:]]

        x_new = []
        for dim in range(self.bounds.shape[0]):
            x_candidates = np.linspace(self.bounds[dim, 0], self.bounds[dim, 1], 100)
            good_likelihood = np.array([self.parzen_window([sample[dim] for sample in good_samples], x_dim) for x_dim in x_candidates])
            bad_likelihood = np.array([self.parzen_window([sample[dim] for sample in bad_samples], x_dim) for x_dim in x_candidates])

            # To avoid division by zero, add a small value (epsilon) to bad_likelihood
            epsilon = 1e-8
            likelihood_ratio = np.log(good_likelihood + epsilon) - np.log(bad_likelihood + epsilon)

            x_new.append(x_candidates[np.argmax(likelihood_ratio)])

        return np.array(x_new)

    def optimize(self):
        for _ in range(self.n_iter):
            x_next = self.suggest()
            y_next = self.func(x_next)
            self.x_samples.append(x_next)
            self.y_samples.append(y_next)

        return self.x_samples, self.y_samples

# Perform TPE Optimization
tpe = TPEOptimization(black_box_function, bounds)
x_samples_tpe, y_samples_tpe = tpe.optimize()
best_params_tpe = x_samples_tpe[np.argmin(y_samples_tpe)]
print("Best parameters (TPE):", best_params_tpe)

def evaluate_model(params):
    n_estimators = int(params[0])
    max_depth = params[1] if params[1] is None else int(params[1])
    min_samples_split = int(params[2])

    model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, min_samples_split=min_samples_split)
    model.fit(X_train, y_train)
    preds = model.predict_proba(X_test)
    return roc_auc_score(y_test, preds, multi_class='ovo')

# Evaluate models
grid_auc = evaluate_model([best_params_grid['n_estimators'], best_params_grid['max_depth'], best_params_grid['min_samples_split']])
random_auc = evaluate_model([best_params_random['n_estimators'], best_params_random['max_depth'], best_params_random['min_samples_split']])
bo_auc = evaluate_model(best_params_bo)
rfo_auc = evaluate_model(best_params_rfo)
tpe_auc = evaluate_model(best_params_tpe)

# Compare the Results
methods = ['Grid Search', 'Random Search', 'Bayesian Optimization', 'Random Forest Optimization', 'TPE']
auc_scores = [grid_auc, random_auc, bo_auc, rfo_auc, tpe_auc]

plt.bar(methods, auc_scores, color=['blue', 'green', 'red', 'purple', 'orange'])
plt.ylabel('AUC Score')
plt.title('Comparison of HPO Techniques')
plt.show()



"""# GridSearch + RandomizedSearch Technique
 Over a fairly simple dataset

> Grid Search;
> Random Search;
> Pipeline for Random Search with PCA Decomposition;




"""

import pandas as pd
import numpy as np

from sklearn import ensemble
from sklearn import metrics
from sklearn import model_selection #cross validation

if __name__ == "__main__":
    df = pd.read_csv("/content/mobile_train.csv")
    print(df.columns) # Corrected the path to be a string
    X = df.drop("price_range", axis=1).values
    Y = df.price_range.values

    classifier = ensemble.RandomForestClassifier(n_jobs=-1)
    param_grid = {
        "n_estimators": [100, 200, 300, 400],
        "max_depth": [1, 3, 5, 7],
        "criterion": ["gini", "entropy"]
    }

    model = model_selection.GridSearchCV(
        estimator=classifier,
        param_grid=param_grid,
        scoring="accuracy",
        verbose=10,
        n_jobs=1,
        cv=5
    )
    model.fit(X, Y)

print(model.best_score_)
print(model.best_estimator_.get_params())

import pandas as pd
import numpy as np

from sklearn import ensemble
from sklearn import metrics
from sklearn import model_selection #cross validation

if __name__ == "__main__":
    df = pd.read_csv("/content/mobile_train.csv")
    print(df.columns) # Corrected the path to be a string
    X = df.drop("price_range", axis=1).values
    Y = df.price_range.values

    classifier = ensemble.RandomForestClassifier(n_jobs=-1)
    param_grid = {
        "n_estimators": np.arange(100,1500,100),
        "max_depth":  np.arange(1, 20),
        "criterion": ["gini", "entropy"]
    }

    model = model_selection.RandomizedSearchCV(
        estimator=classifier,
        param_distributions=param_grid,
        n_iter=10,
        scoring="accuracy",
        verbose=10,
        n_jobs=1,
        cv=5
    )
    model.fit(X, Y)
    print(model.best_score_)
    print(model.best_estimator_.get_params())

import pandas as pd
import numpy as np

from sklearn import ensemble
from sklearn import metrics
from sklearn import model_selection #cross validation
from sklearn import decomposition
from sklearn import preprocessing
from sklearn import pipeline

if __name__ == "__main__":
    df = pd.read_csv("/content/mobile_train.csv")
    print(df.columns) # Corrected the path to be a string
    X = df.drop("price_range", axis=1).values
    Y = df.price_range.values

    scl = preprocessing.StandardScaler()
    pca = decomposition.PCA()
    rf = ensemble.RandomForestClassifier(n_jobs=-1)

    classifier = pipeline.Pipeline([
        ("scaling", scl),
        ("pca", pca),
        ("rf", rf)
    ])

    param_grid = {
        "pca__n_components" : np.arange(5,10),
        "rf__n_estimators": np.arange(100,1500,100),
        "rf__max_depth":  np.arange(1, 20),
        "rf__criterion": ["gini", "entropy"]
    }

    model = model_selection.RandomizedSearchCV(
        estimator=classifier,
        param_distributions=param_grid,
        n_iter=10,
        scoring="accuracy",
        verbose=10,
        n_jobs=1,
        cv=5
    )
    model.fit(X, Y)
    print(model.best_score_)
    print(model.best_estimator_.get_params())

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

from sklearn import ensemble
from sklearn import metrics
from sklearn import model_selection
from sklearn import decomposition
from sklearn import preprocessing
from sklearn import pipeline
from sklearn.metrics import roc_auc_score, make_scorer

# Custom scorer using ROC AUC
def custom_roc_auc(y_true, y_pred):
    return roc_auc_score(y_true, y_pred, multi_class='ovo', average='macro')

roc_auc_scorer = make_scorer(custom_roc_auc, needs_proba=True)

if __name__ == "__main__":
    df = pd.read_csv("/content/mobile_train.csv")
    print("Columns in the dataset:", df.columns)

    X = df.drop("price_range", axis=1).values
    Y = df["price_range"].values

    scl = preprocessing.StandardScaler()
    pca = decomposition.PCA()
    rf = ensemble.RandomForestClassifier(n_jobs=-1)

    classifier = pipeline.Pipeline([
        ("scaling", scl),
        ("pca", pca),
        ("rf", rf)
    ])

    param_grid = {
        "pca__n_components": np.arange(5, 10),
        "rf__n_estimators": np.arange(100, 1500, 100),
        "rf__max_depth": np.arange(1, 20),
        "rf__criterion": ["gini", "entropy"]
    }

    model = model_selection.RandomizedSearchCV(
        estimator=classifier,
        param_distributions=param_grid,
        n_iter=10,
        scoring=roc_auc_scorer,
        verbose=10,
        n_jobs=-1,
        cv=5
    )
    model.fit(X, Y)

    print("Best ROC AUC score:", model.best_score_)
    print("Best estimator parameters:", model.best_estimator_.get_params())

    # Plot learning curve for the best model
    def plot_learning_curve(estimator, X, y, cv=5, n_jobs=-1, scoring='accuracy'):
        train_sizes, train_scores, test_scores = model_selection.learning_curve(
            estimator, X, y, cv=cv, n_jobs=n_jobs, scoring=scoring)

        train_scores_mean = np.mean(train_scores, axis=1)
        test_scores_mean = np.mean(test_scores, axis=1)

        plt.figure()
        plt.plot(train_sizes, train_scores_mean, 'o-', color='r', label="Training score")
        plt.plot(train_sizes, test_scores_mean, 'o-', color='g', label="Cross-validation score")
        plt.title('Learning Curve')
        plt.xlabel('Training examples')
        plt.ylabel('Score')
        plt.legend(loc='best')
        plt.grid()
        plt.show()

    best_estimator = model.best_estimator_
    plot_learning_curve(best_estimator, X, Y, cv=5, scoring='accuracy')

"""# Bayesian Optimization with Gaussian Process"""

!pip install scikit-optimize

import pandas as pd
import numpy as np

from sklearn import ensemble
from sklearn import metrics
from sklearn import model_selection # cross validation
from skopt import space
from skopt import gp_minimize
from functools import partial

# Optimization function
def optimize(params, param_names, x, y):
    params = dict(zip(param_names, params))
    model = ensemble.RandomForestClassifier(**params)
    kf = model_selection.StratifiedKFold(n_splits=5)
    accuracies = []

    for train_idx, test_idx in kf.split(X=x, y=y):
        xtrain = x[train_idx]
        ytrain = y[train_idx]
        xtest = x[test_idx]
        ytest = y[test_idx]

        model.fit(xtrain, ytrain)
        preds = model.predict(xtest)
        fold_acc = metrics.accuracy_score(ytest, preds)
        accuracies.append(fold_acc)

    # Return the negative accuracy to minimize
    return -1.0 * np.mean(accuracies)

if __name__ == "__main__":
    df = pd.read_csv("/content/mobile_train.csv")
    print("Columns in the dataset:", df.columns)
    X = df.drop("price_range", axis=1).values
    Y = df["price_range"].values

    param_space = [
        space.Integer(3, 15, name="max_depth"),
        space.Integer(100, 600, name="n_estimators"),
        space.Categorical(["gini", "entropy"], name="criterion"),
        space.Real(0.01, 1, prior="uniform", name="max_features")
    ]

    param_names = ["max_depth", "n_estimators", "criterion", "max_features"]

    optimization_function = partial(
        optimize,
        param_names=param_names,
        x=X,
        y=Y
    )

    result = gp_minimize(
        optimization_function,
        dimensions=param_space,
        n_calls=50,  # number of evaluations of minimize
        n_random_starts=10,
        verbose=True
    )

    print("Best Parameters:", dict(zip(param_names, result.x)))
    print("Best Score:", -result.fun)

"""# HyperOpt Simulation



> Just for learning!






"""

import pandas as pd
import numpy as np

from sklearn import ensemble
from sklearn import metrics
from sklearn import model_selection # cross validation
from skopt import space
from skopt import gp_minimize
from functools import partial

from hyperopt import hp, fmin, tpe, Trials, STATUS_OK
from hyperopt.pyll.base import scope

# Optimization function
def optimize(params, x, y):
    model = ensemble.RandomForestClassifier(**params)
    kf = model_selection.StratifiedKFold(n_splits=5)
    accuracies = []

    for train_idx, test_idx in kf.split(X=x, y=y):
        xtrain = x[train_idx]
        ytrain = y[train_idx]
        xtest = x[test_idx]
        ytest = y[test_idx]

        model.fit(xtrain, ytrain)
        preds = model.predict(xtest)
        fold_acc = metrics.accuracy_score(ytest, preds)
        accuracies.append(fold_acc)

    # Return the negative accuracy to minimize
    return -1.0 * np.mean(accuracies)

if __name__ == "__main__":
    df = pd.read_csv("/content/mobile_train.csv")
    print("Columns in the dataset:", df.columns)
    X = df.drop("price_range", axis=1).values
    Y = df["price_range"].values

    param_space = {
        "max_depth" : scope.int(hp.quniform("max_depth", 3, 15, 1)),
        "n_estimators" : scope.int(hp.quniform("n_estimators", 100, 600, 1)),
        "criterion" : hp.choice("criterion", ["gini", "entropy"]),
        "max_features" : hp.uniform("max_features", 0.01, 1)
    }

    # param_names = ["max_depth", "n_estimators", "criterion", "max_features"]

    optimization_function = partial(
        optimize,
        x=X,
        y=Y
    )

    trials = Trials()
    # best_params = fmin(fn=optimization_function, space=param_space, algo=tpe.suggest, max_evals=50, trials=trials)

    result = fmin(
        fn=optimization_function,
        space=param_space,
        algo = tpe.suggest,
        max_evals=20,
        trials=trials
    )

    print(result)

"""# Using Optuna"""

!pip install optuna

import pandas as pd
import numpy as np

from sklearn import ensemble
from sklearn import metrics
from sklearn import model_selection # cross validation
import optuna
from functools import partial

# Optimization function for Optuna
def optimize_optuna(trial, x, y):
    entropy = trial.suggest_categorical("criterion", ["gini", "entropy"])
    n_estimators = trial.suggest_int("n_estimators", 100, 1500)
    max_depth = trial.suggest_int("max_depth", 3, 15)
    max_features = trial.suggest_float("max_features", 0.01, 1.0)

    model = ensemble.RandomForestClassifier(
        n_estimators=n_estimators,
        max_depth=max_depth,
        max_features=max_features,
        criterion=entropy
    )
    kf = model_selection.StratifiedKFold(n_splits=5)
    accuracies = []

    for train_idx, test_idx in kf.split(X=x, y=y):
        xtrain = x[train_idx]
        ytrain = y[train_idx]
        xtest = x[test_idx]
        ytest = y[test_idx]

        model.fit(xtrain, ytrain)
        preds = model.predict(xtest)
        fold_acc = metrics.accuracy_score(ytest, preds)
        accuracies.append(fold_acc)

    # Return the negative accuracy to minimize
    return -1.0 * np.mean(accuracies)

if __name__ == "__main__":
    df = pd.read_csv("/content/mobile_train.csv")
    print("Columns in the dataset:", df.columns)
    X = df.drop("price_range", axis=1).values
    Y = df["price_range"].values

    optimization_function = partial(optimize_optuna, x=X, y=Y)
    study = optuna.create_study(direction="minimize")
    study.optimize(optimization_function, n_trials=15)

    print("Best Parameters from Optuna:", study.best_params)
    print("Best Score from Optuna:", -study.best_value)

import pandas as pd
import numpy as np
from sklearn import ensemble, metrics, model_selection
from sklearn.model_selection import learning_curve
import matplotlib.pyplot as plt
from hyperopt import hp, fmin, tpe, Trials, STATUS_OK
from functools import partial

def plot_learning_curve(estimator, X, y, title="Learning Curve", cv=5, n_jobs=-1):
    train_sizes, train_scores, test_scores = learning_curve(
        estimator, X, y, cv=cv, n_jobs=n_jobs, scoring="roc_auc_ovr"
    )
    train_scores_mean = np.mean(train_scores, axis=1)
    train_scores_std = np.std(train_scores, axis=1)
    test_scores_mean = np.mean(test_scores, axis=1)
    test_scores_std = np.std(test_scores, axis=1)

    plt.figure()
    plt.title(title)
    plt.xlabel("Training examples")
    plt.ylabel("Score")
    plt.ylim(0.0, 1.1)

    plt.grid()

    plt.fill_between(
        train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color="r"
    )
    plt.fill_between(
        train_sizes, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, alpha=0.1, color="g"
    )

    plt.plot(train_sizes, train_scores_mean, "o-", color="r", label="Training score")
    plt.plot(train_sizes, test_scores_mean, "o-", color="g", label="Cross-validation score")

    plt.legend(loc="best")
    return plt

# Optimization function for Hyperopt
def optimize_hyperopt(params, x, y):
    entropy = params["criterion"]
    n_estimators = int(params["n_estimators"])
    max_depth = int(params["max_depth"])
    max_features = params["max_features"]

    model = ensemble.RandomForestClassifier(
        n_estimators=n_estimators,
        max_depth=max_depth,
        max_features=max_features,
        criterion=entropy
    )
    kf = model_selection.StratifiedKFold(n_splits=5)
    roc_aucs = []

    for train_idx, test_idx in kf.split(X=x, y=y):
        xtrain = x[train_idx]
        ytrain = y[train_idx]
        xtest = x[test_idx]
        ytest = y[test_idx]

        model.fit(xtrain, ytrain)
        preds = model.predict_proba(xtest)
        fold_roc_auc = metrics.roc_auc_score(ytest, preds, multi_class='ovr')
        roc_aucs.append(fold_roc_auc)

    return {"loss": -1.0 * np.mean(roc_aucs), "status": STATUS_OK}

if __name__ == "__main__":
    df = pd.read_csv("/content/mobile_train.csv")
    print("Columns in the dataset:", df.columns)
    X = df.drop("price_range", axis=1).values
    Y = df["price_range"].values

    param_space = {
        "criterion": hp.choice("criterion", ["gini", "entropy"]),
        "n_estimators": hp.quniform("n_estimators", 100, 1500, 1),
        "max_depth": hp.quniform("max_depth", 3, 15, 1),
        "max_features": hp.uniform("max_features", 0.01, 1.0)
    }

    optimization_function = partial(optimize_hyperopt, x=X, y=Y)

    trials = Trials()
    result = fmin(
        fn=optimization_function,
        space=param_space,
        algo=tpe.suggest,
        max_evals=20,
        trials=trials
    )

    best_params = {
        "criterion": ["gini", "entropy"][result["criterion"]],
        "n_estimators": int(result["n_estimators"]),
        "max_depth": int(result["max_depth"]),
        "max_features": result["max_features"]
    }

    print("Best Parameters from Hyperopt:", best_params)

    # Create models
    random_model = ensemble.RandomForestClassifier()
    submitted_model = ensemble.RandomForestClassifier(
        n_estimators=500, max_depth=10, max_features=0.5, criterion='gini'
    )
    hyperopt_model = ensemble.RandomForestClassifier(**best_params)

    # Plot learning curves
    plot_learning_curve(random_model, X, Y, title="Random Model Learning Curve")
    plot_learning_curve(submitted_model, X, Y, title="Submitted Model Learning Curve")
    plot_learning_curve(hyperopt_model, X, Y, title="Hyperopt Model Learning Curve")

    plt.show()

"""# CMA-ES

> Covariance Matrix Adaptation Evolution Strategy


"""

!pip install cma

import pandas as pd
import numpy as np
from sklearn import ensemble, metrics, model_selection
import cma
import matplotlib.pyplot as plt

# Utility function to plot learning curve
def plot_learning_curve(estimator, X, y, title="Learning Curve", cv=5, n_jobs=-1):
    train_sizes, train_scores, test_scores = model_selection.learning_curve(
        estimator, X, y, cv=cv, n_jobs=n_jobs, scoring="roc_auc_ovr"
    )
    train_scores_mean = np.mean(train_scores, axis=1)
    train_scores_std = np.std(train_scores, axis=1)
    test_scores_mean = np.mean(test_scores, axis=1)
    test_scores_std = np.std(test_scores, axis=1)

    plt.figure()
    plt.title(title)
    plt.xlabel("Training examples")
    plt.ylabel("Score")
    plt.ylim(0.0, 1.1)

    plt.grid()

    plt.fill_between(
        train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color="r"
    )
    plt.fill_between(
        train_sizes, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, alpha=0.1, color="g"
    )

    plt.plot(train_sizes, train_scores_mean, "o-", color="r", label="Training score")
    plt.plot(train_sizes, test_scores_mean, "o-", color="g", label="Cross-validation score")

    plt.legend(loc="best")
    plt.show()

# Objective function for CMA-ES
def optimize_cmaes(params, x, y):
    n_estimators = int(params[0])
    max_depth = int(params[1])
    max_features = params[2]
    criterion = "gini" if params[3] < 0.5 else "entropy"

    model = ensemble.RandomForestClassifier(
        n_estimators=n_estimators,
        max_depth=max_depth,
        max_features=max_features,
        criterion=criterion
    )
    kf = model_selection.StratifiedKFold(n_splits=5)
    roc_aucs = []

    for train_idx, test_idx in kf.split(X=x, y=y):
        xtrain, xtest = x[train_idx], x[test_idx]
        ytrain, ytest = y[train_idx], y[test_idx]

        model.fit(xtrain, ytrain)
        preds = model.predict_proba(xtest)
        fold_roc_auc = metrics.roc_auc_score(ytest, preds, multi_class='ovr')
        roc_aucs.append(fold_roc_auc)

    return -1.0 * np.mean(roc_aucs)  # CMA-ES minimizes, so return negative ROC AUC

if __name__ == "__main__":
    # Load data
    df = pd.read_csv("/content/mobile_train.csv")
    print("Columns in the dataset:", df.columns)
    X = df.drop("price_range", axis=1).values
    Y = df["price_range"].values

    # Define initial parameters and bounds
    initial_params = [500, 10, 0.5, 0]  # n_estimators, max_depth, max_features, criterion (0: gini, 1: entropy)
    lower_bounds = [100, 3, 0.01, 0]
    upper_bounds = [1500, 15, 1.0, 1]
    bounds = [lower_bounds, upper_bounds]

    # Run CMA-ES optimization
    es = cma.CMAEvolutionStrategy(initial_params, 0.5, {'bounds': bounds, 'popsize': 20})
    while not es.stop():
        solutions = es.ask()
        scores = [optimize_cmaes(s, x=X, y=Y) for s in solutions]
        es.tell(solutions, scores)

    # Best solution
    best_params = es.result.xbest
    print("Best Parameters from CMA-ES:", best_params)

    # Translate parameters
    best_params_dict = {
        "n_estimators": int(best_params[0]),
        "max_depth": int(best_params[1]),
        "max_features": best_params[2],
        "criterion": "gini" if best_params[3] < 0.5 else "entropy"
    }
    print("Translated Best Parameters:", best_params_dict)

    # Create models
    random_model = ensemble.RandomForestClassifier()
    submitted_model = ensemble.RandomForestClassifier(
        n_estimators=500, max_depth=10, max_features=0.5, criterion='gini'
    )
    cmaes_model = ensemble.RandomForestClassifier(**best_params_dict)

    # Plot learning curves
    plot_learning_curve(random_model, X, Y, title="Random Model Learning Curve")
    plot_learning_curve(submitted_model, X, Y, title="Submitted Model Learning Curve")
    plot_learning_curve(cmaes_model, X, Y, title="CMA-ES Optimized Model Learning Curve")

"""# Additional :

> Keras Hyperparameter Tuning

> Genetic Algorithm (TPOT Classifier)

> BOTorch

TPOT Classifier
"""

import warnings
warnings.filterwarnings('ignore')

import pandas as pd
df=pd.read_csv('/content/diabetes.csv')
df.head()

import numpy as np
df['Glucose']=np.where(df['Glucose']==0,df['Glucose'].median(),df['Glucose'])
df.head()

X=df.drop('Outcome',axis=1)
y=df['Outcome']

pd.DataFrame(X,columns=df.columns[:-1])

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.20,random_state=0)

from sklearn.ensemble import RandomForestClassifier
rf_classifier=RandomForestClassifier(n_estimators=10).fit(X_train,y_train)
prediction=rf_classifier.predict(X_test)

y.value_counts()

from sklearn.metrics import confusion_matrix,classification_report,accuracy_score
print(confusion_matrix(y_test,prediction))
print(accuracy_score(y_test,prediction))
print(classification_report(y_test,prediction))

# Manual Hyperparameter Tuning
model=RandomForestClassifier(n_estimators=300,criterion='entropy',
                             max_features='sqrt',min_samples_leaf=10,random_state=100).fit(X_train,y_train)
predictions=model.predict(X_test)
print(confusion_matrix(y_test,predictions))
print(accuracy_score(y_test,predictions))
print(classification_report(y_test,predictions))

import numpy as np
from sklearn.model_selection import RandomizedSearchCV
# Number of trees in random forest
n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]
# Number of features to consider at every split
max_features = ['auto', 'sqrt','log2']
# Maximum number of levels in tree
max_depth = [int(x) for x in np.linspace(10, 1000,10)]
# Minimum number of samples required to split a node
min_samples_split = [2, 5, 10,14]
# Minimum number of samples required at each leaf node
min_samples_leaf = [1, 2, 4,6,8]
# Create the random grid
param = {'n_estimators': n_estimators,
               'max_features': max_features,
               'max_depth': max_depth,
               'min_samples_split': min_samples_split,
               'min_samples_leaf': min_samples_leaf,
              'criterion':['entropy','gini']}
print(param)

!pip install tpot

pip install tpot --upgrade

!pip install scikit-learn==1.1.3

pip uninstall scikit-learn tpot
pip install scikit-learn==1.1.3 tpot

from tpot import TPOTClassifier

tpot_classifier = TPOTClassifier(generations= 5, population_size= 24, offspring_size= 12,
                                 verbosity= 2, early_stop= 12,
                                 config_dict={'sklearn.ensemble.RandomForestClassifier': param},
                                 cv = 4, scoring = 'accuracy')
tpot_classifier.fit(X_train,y_train)

accuracy = tpot_classifier.score(X_test, y_test)
print(accuracy)

